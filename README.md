# Docker-ETL-Pipeline
An extract, transform load data pipeline composed with Docker. The docker-compose yaml file defines the source database, destination database and python script as services for the pipeline. When run by the Dockerfile, the python script etl_script.py establishes a connection to the source database. It then reads the Users table into a dataframe, upon which various transformations are made. It then loads the transformed data to the destination database and executes an SQL statement which defines the primary key for the table. The resulting data can be viewed by executing the command docker exec -t etl-destination_postgres-1 psql -U postgres and connexting to the database "destination_db".
